\chapter{CONCLUSÃO E TRABALHOS FUTUROS}
\label{chp:conclusão}

Os códigos \gls{icd} são utilizados por diversos segmentos da medicina, como na gestão hospitalar, com solicitações de reembolso das operadoras de saúde e alocação de recursos médicos; produção de conhecimento, através do agrupamento por classe \gls{icd}, padrões de evolução e estudo do risco das patologias; e também a nível global para reportar a causa do óbito de pacientes em diversos países. Tais utilizações dependem da classificação manual desses códigos por especialistas e, devido a sua natureza operacional, sujeita a erros e de elevado investimento financeiro \cite{Xie2018ANeuralArchitecture}. 

O presente trabalho abordou a classificação dos códigos \gls{icd}-10 em prontuários médicos de alta de paciente utilizando uma abordagem semelhante a uma \glsxtrlong{nmt}, através de um par codificador-decodificador, utilizando como entrada o próprio prontuário e a saída sendo um texto produzido pela rede neural contendo códigos \gls{icd} separados por espaço. Buscou-se avaliar tanto o desempenho da arquitetura do rede neural quanto a influência do \textit{tokenizador} na classificação dos códigos \gls{icd}. Duas topologias, ambas utilizando mecanismos de atenção, sendo elas \xfmrxfmr{} e \lstmlstm{}, e dois \textit{tokenizadores}, SentencePiece e WordPiece, foram avaliados utilizando métricas da medida-F1 e distância de Levenshtein comparando o resultado com uma base de dados supervisionada. O autor desconhece qualquer outro experimento em que uma abordagem utilizando \gls{nmt} para classificação de códigos \gls{icd} tenha sido utilizada anteriormente.

O resultado apresentado indica que o modelo \xfmrxfmr, em sua melhor configuração, possui micromédia da medida-F1 e distância de Levenshtein melhores se comparado ao \lstmlstm, também em sua melhor configuração ($24,68\%$ e $17,52\%$, respectivamente, conforme Tabelas \ref{table:xfmr_xfmr_statistics} e \ref{table:lstm_lstm_statistics}). O agente causador desse efeito é desconhecido, podendo ser inerente à arquitetura, ou relacionado à capacidade computacional de paralelização do \textit{Transformer} ser superior ao \gls{lstm}, permitindo que mais épocas sejam apresentadas em um mesmo intervalo de tempo. O treinamento de uma época no \textit{Transformer} levou aproximadamente $18$ minutos contra duas horas no \gls{lstm}. Uma investigação comparando a evolução do resultado do treinamento entre as arquiteturas até o limiar do aprendizado, isto é, até o sobre-ajuste, faz-se necessária para determinar qual deles possui a melhor capacidade de aprendizado dada uma mesma quantidade de épocas. 

Devido a limitações computacionais, o modelo \textit{Transformer} utilizou menos camadas e, consequentemente, menos parâmetros do apresentado por \textcite{Vaswani2017Attention}. Tal configuração pode influenciar o desempenho da classificação, podendo ser investigada futuramente. De modo similar, a quantidade de unidades escondidas e camadas do \gls{lstm} possuem potencial para alterar o resultado da tarefa. Não somente a quantidade de parâmetros, mas a mistura entre o modelo \textit{Transformer} e o recorrente, entre codificador e decodificador, podem alterar o resultado da classificação, assim como a utilização de outros modelos recorrentes, como o \gls{gru}, pode ser investigado futuramente.

Um comparativo utilizando a medida-F1 de cada código \gls{icd} presente na base de teste entre os modelos \xfmrxfmr{} e \lstmlstm{} foi realizado (Figura \ref{fig:result_f1_comparison_xfmr_lstm}). O modelo utilizando o Transformar obteve medida-F1 superior em quatro vezes mais códigos \gls{icd} do que o qual utilizou \gls{lstm}, sendo que, em $56,02\%$ dos casos, ambos modelos apresentaram medida-F1 igual a zero. Mesmo que o \textit{Transformer} tenha tido resultado superior, não é conclusiva a razão pela qual certos códigos \gls{icd} foram melhores classificados em um modelo ao invés de outro, podendo esse ser um evento aleatório, ou indicar capacidades distintas de modelagem de linguagem entre eles.

% Comparação com a literatura.
Para comparar com trabalhos relacionados (Capítulo \ref{chp:rel}) que também utilizaram o conjunto de dados MIMIC-III, o modelo \xfmrxfmr{} com SentencePiece foi utilizado, já que ele apresentou os melhores resultados para a micromédia da medida-F1 das $10$, $50$ e $100$ classes mais comuns, sendo $65,54\%$, $51,54\%$ e $47,60\%$, respectivamente; e também medida-F1 de $24,69\%$ para todas as classes disponíveis. A investigação realizada por \textcite{Shi2017TowardsAutomatedICD}, que utilizou \gls{lstm}, resultou em uma medida-F1 para as $50$ classes mais comuns $3,06\%$ superior a este trabalho. \textcite{Baumel2018MultiLabelCO} obteve medida-F1 de $53,86\%$ utilizando \gls{ha-gru}, porém não é possível identificar qual critério de seleção de classes foi utilizado.

Para os $10$ códigos mais comuns, \textcite{Huang2019AnEE} encontrou a micromédia da medida-F1 de $72,0\%$, $9,86\%$ superior a esse trabalho, e para os $50$ códigos $33,0\%$, $30,67\%$ menor do que o presente trabalho, ambos utilizando redes profundas com \gls{gru}. \textcite{Hsu2020MultiLabel} utilizou \gls{cnn} e obteve $55,2\%$ para as $100$ classes mais comuns, $15,97\%$ superior ao resultado desse trabalho. \textcite{Singh2020MultiLabel} utilizou o \gls{bert} para os $10$ e $50$ códigos mais comuns e encontrou $85,82\%$ e $92,2\%$. Em qualquer que seja a comparação, não é claro quais os critérios foram utilizados para seleção dos prontuários médicos, classes utilizados, ou limitações no nível hierárquico dos códigos \gls{icd}. Tal não uniformização do modo de avaliação entre as pesquisas tornam a comparação direta uma tarefa trabalhosa.
% Acabou a comparação.

Qualquer que seja o modelo, a quantidade de exemplos de uma mesma classe é um fator importante para o desempenho da classificação. As Figuras \ref{fig:result_appears_vs_f1_xfmr_xfmr} e \ref{fig:result_appears_vs_f1_lstm_lstm} indicam uma tendência de que, quanto maior a frequência que uma classe aparece, maior pode ser sua medida-F1. Tal situação aponta a necessidade de treinamento com um número maior de exemplos, idealmente com distribuição linear entre as classes. Uma possível abordagem futura é a divisão do treinamento e sua aplicação por grupo de especialidade médica, limitando assim as possibilidades de aparição de códigos \gls{icd} diminuindo um possível efeito do desbalanceamento entre classes.

O testes realizados entre os \textit{tokenizadores} SentencePiece e WordPiece resultaram na detecção de melhores resultados da micromédia da medida-F1 e distância de Levenshtein do SentencePiece, independente da arquitetura de codificador-decodificador empregado. Tal resultado pode ser devido ao vocabulário produzido ao término do treinamento do SentencePiece possuir mais \textit{tokens} do que o WordPiece, consequentemente, a quantidade de \textit{tokens} por conteúdo e anotação, serem maiores do que o WordPiece. Essa quantidade superior pode permitir à camada de \textit{embeddings}, utilizada tanto no codificador quanto no decodificador, uma maior liberdade de realizar ligações semânticas e sintáticas nos vetores produzidos. Uma investigação futura pode ser realizada avaliando a influência do tamanho do vocabulário no desempenho da tarefa de classificação \gls{icd}.